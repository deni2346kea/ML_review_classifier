{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('movie_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model by Stochastic Gradient Descent classifier\n",
    "classifier = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
    "X_train = df['review'].values\n",
    "y_train = df['sentiment'].values\n",
    "\n",
    "X_train = vect.transform(X_train)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dir and subdir for pickled objects (export of the built model)\n",
    "dest = os.path.join('model', 'pickles')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize the model\n",
    "pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'), protocol=4)\n",
    "pickle.dump(classifier, open(os.path.join(dest, 'classifier.pkl'), 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load and reuse the pickles\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "stop = pickle.load(open(\n",
    "                os.path.join('model', \n",
    "                'pickles', \n",
    "                'stopwords.pkl'), 'rb'))\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) \\\n",
    "                   + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "# converts document into word vector\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         tokenizer=tokenizer)\n",
    "classifier = pickle.load(open(\n",
    "                os.path.join('model', \n",
    "                'pickles', \n",
    "                'classifier.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuse the model for prediction\n",
    "import numpy as np\n",
    "label = {0:'negative', 1:'positive'}\n",
    "\n",
    "# predict() returns predicted label\n",
    "# predict_proba(X) returns probability\n",
    "\n",
    "example1 = ['Nice movie']\n",
    "X = vect.transform(example1)\n",
    "print('Prediction 1: %s\\nProbability 1: %.2f%%' %(label[classifier.predict(X)[0]], np.max(classifier.predict_proba(X))*100))\n",
    "\n",
    "example2 = ['Terrible film']\n",
    "X = vect.transform(example2)\n",
    "print('Prediction 2: %s\\nProbability 2: %.2f%%' %(label[classifier.predict(X)[0]], np.max(classifier.predict_proba(X))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check current directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "if os.path.exists('MyReviewDB.sqlite'):\n",
    "    os.remove('MyReviewDB.sqlite')\n",
    "\n",
    "# create connection\n",
    "conn = sqlite3.connect('MyReviewDB.sqlite')\n",
    "\n",
    "# create cursor\n",
    "c = conn.cursor()\n",
    "\n",
    "# execute commands\n",
    "c.execute('CREATE TABLE review_db (review TEXT, sentiment INTEGER, date TEXT)')\n",
    "\n",
    "example1 = 'I love this movie'\n",
    "c.execute(\"INSERT INTO review_db (review, sentiment, date) VALUES (?, ?, DATETIME('now'))\", (example1, 1))\n",
    "\n",
    "example2 = 'I hate this movie'\n",
    "c.execute(\"INSERT INTO review_db (review, sentiment, date) VALUES (?, ?, DATETIME('now'))\", (example2, 0))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open DB\n",
    "conn = sqlite3.connect('reviews.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute(\"SELECT * FROM review_db WHERE date BETWEEN '2018-01-01 10:10:10' AND DATETIME('now')\")\n",
    "results = c.fetchall()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mywebapp.py\n",
    "# define app that will be deployed on a server and save it in a file\n",
    "# class ReviewForm(Form):\n",
    "#    moviereview = TextAreaField('', [validators.DataRequired(), validators.length(min=15)])\n",
    "\n",
    "# import class Flask\n",
    "from flask import Flask, render_template, request\n",
    "from wtforms import Form, TextAreaField, validators\n",
    "import pickle\n",
    "import sqlite3\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# load and reuse the pickles\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "stop = pickle.load(open(\n",
    "                os.path.join('model', \n",
    "                'pickles', \n",
    "                'stopwords.pkl'), 'rb'))\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) \\\n",
    "                   + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "# converts document into word vector\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         tokenizer=tokenizer)\n",
    "classifier = pickle.load(open(\n",
    "                os.path.join('model', \n",
    "                'pickles', \n",
    "                'classifier.pkl'), 'rb'))\n",
    "\n",
    "db = os.path.join(os.getcwd(), 'reviews.sqlite')\n",
    "\n",
    "def classify(document):\n",
    "    label = {0: 'negative', 1: 'positive'}\n",
    "    X = vect.transform([document])\n",
    "    y = classifier.predict(X)[0]\n",
    "    proba = np.max(classifier.predict_proba(X))\n",
    "    return label[y], proba\n",
    "\n",
    "def train(document, y):\n",
    "    X = vect.transform([document])\n",
    "    classifier.partial_fit(X, [y])\n",
    "\n",
    "def sqlite_entry(path, document, y):\n",
    "    conn = sqlite3.connect(path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"INSERT INTO review_db (review, sentiment, date)\"\\\n",
    "    \" VALUES (?, ?, DATETIME('now'))\", (document, y))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "# create an instance (our app)\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    form = None\n",
    "    if request.method == 'POST' and 'review' in request.form:\n",
    "        form = request.form['review']\n",
    "    return render_template('default.html', form=form)\n",
    "\n",
    "\n",
    "@app.route('/results', methods=['POST'])\n",
    "def results():\n",
    "    form = request.form\n",
    "    if request.method == 'POST':\n",
    "        review = request.form['review']\n",
    "        y, proba = classify(review)\n",
    "        return render_template('results.html',\n",
    "                                content=review,\n",
    "                                prediction=y,\n",
    "                                probability=round(proba*100, 2))\n",
    "    return render_template('results.html', name=name)\n",
    "\n",
    "@app.route('/bye', methods=['POST'])\n",
    "def feedback():\n",
    "    feedback = request.form['feedback_button']\n",
    "    review = request.form['review']\n",
    "    prediction = request.form['prediction']\n",
    "\n",
    "    inv_label = {'negative': 0, 'positive': 1}\n",
    "    y = inv_label[prediction]\n",
    "    if feedback == 'Incorrect':\n",
    "        y = int(not(y))\n",
    "    train(review, y)\n",
    "    sqlite_entry(db, review, y)\n",
    "    return render_template('bye.html')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python mywebapp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the movie review classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to update the classifier with the data stored in the local SQLite database\n",
    "import pickle\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "# import HashingVectorizer from local dir\n",
    "# from vectorizer import vect\n",
    "\n",
    "# converts document into word vector\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None,\n",
    "                         tokenizer=tokenizer)\n",
    "\n",
    "def update_model(db_path, model, batch_size=10000):\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute('SELECT * from review_db')\n",
    "    \n",
    "    results = c.fetchmany(batch_size)\n",
    "    while results:\n",
    "        data = np.array(results)\n",
    "        X = data[:, 0]\n",
    "        y = data[:, 1].astype(int)\n",
    "    \n",
    "        classes = np.array([0, 1])\n",
    "        X_train = vect.transform(X)\n",
    "        clf.partial_fit(X_train, y, classes=classes)\n",
    "        results = c.fetchmany(batch_size)\n",
    "    \n",
    "    conn.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cur_dir = os.getcwd()\n",
    "\n",
    "clf = pickle.load(open(os.path.join(cur_dir, 'model/pickles', 'classifier.pkl'), 'rb'))\n",
    "db = os.path.join(cur_dir, 'reviews.sqlite')\n",
    "\n",
    "update_model(db_path=db, model=clf, batch_size=10000)\n",
    "\n",
    "# update your classifier.pkl file\n",
    "pickle.dump(clf, open(os.path.join(cur_dir, 'model/pickles', 'classifier.pkl'), 'wb') , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
